{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2cc17b1",
   "metadata": {},
   "source": [
    "### Training DistlBERT model for LLM augmented features\n",
    "\n",
    "Firstly, we will prepare the 2 LLM-augmented feature columns by fine-tuning the DistilBERT model. This process will be greatly sped up by leveraging a GPU for the training phase.  \n",
    "If you have a GPU but torch is not detecting it, you can try running the below lines of code in terminal to try fix it.\n",
    "\n",
    "1. Check if NVIDIA drivers are installed by running `nvidia-simi` and noting the version number e.g. 12.1, 11.8\n",
    "    - If they are not installed, install them from the NVIDIA Website\n",
    "2. Run `pip uninstall torch`\n",
    "3. Reinstall torch\n",
    "    - For version number 12.1, run `pip install torch --index-url https://download.pytorch.org/whl/cu121`\n",
    "    - For version 11.8, run `pip install torch --index-url https://download.pytorch.org/whl/cu118`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9401c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "\n",
    "# Import libraries\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3935e9",
   "metadata": {},
   "source": [
    "We will being by training the model to produce probabilities that the user is bot based on  `description` feature only first.  \n",
    "  \n",
    "This code assumes that you have a folder in the current directory named 'data' and contains 'train.csv' for the training dataset and 'test.csv' as the pre-split test dataset.  \n",
    "  \n",
    "Please change `train_data_path` and `test_data_path` if this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43159cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 26206 samples\n",
      "Test dataset size: 11232 samples\n",
      "Model configured: distilbert-base-uncased\n",
      "Tokenizer loaded successfully!\n",
      "Model and tokenizer configured successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_extract_data():\n",
    "    \"\"\"Load train and test data\"\"\"\n",
    "    train_data_path = \"data/train.csv\"\n",
    "    test_data_path = \"data/test.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    # Extract out description and target from train, description from test\n",
    "    train_texts = train_df['description'].fillna(\"\").astype(str).tolist()\n",
    "    train_labels = train_df['target'].tolist()\n",
    "    test_texts = test_df['description'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    print(f\"Train dataset size: {len(train_df)} samples\")\n",
    "    print(f\"Test dataset size: {len(test_df)} samples\")\n",
    "\n",
    "    return train_texts, train_labels, test_texts\n",
    "\n",
    "# Load the preprocessed data\n",
    "train_texts, train_labels, test_texts = load_extract_data()\n",
    "\n",
    "# Model Setup for Binary Classification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "\n",
    "# Load tokenizer (shared across all folds)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Model configured: {model_name}\")\n",
    "print(\"Tokenizer loaded successfully!\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128  # Reasonable for Twitter descriptions\n",
    "    )\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Create a fresh model for each fold\"\"\"\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,  # Binary classification\n",
    "        id2label={0: \"human\", 1: \"bot\"},\n",
    "        label2id={\"human\": 0, \"bot\": 1}\n",
    "    )\n",
    "\n",
    "print(\"Model and tokenizer configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6795531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501b4babc8af4a6e821db9513e346fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-fold cross-validation training...\n",
      "============================================================\n",
      "\n",
      "Fold 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d8d1f3c71b490d8a5d35c81d6372ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7835965172434aae948cb1856f1286f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\1366564830.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.538300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.468300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.363600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 1 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 0.7667, AUC: 0.8160\n",
      "\n",
      "Fold 2/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42ae64504284703b115b5bc8670ac4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2596b956d4b4c8e87a54a5a141867ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\1366564830.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.443200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.350200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 2 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Accuracy: 0.7689, AUC: 0.8199\n",
      "\n",
      "Fold 3/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfa7bb5a7e24ad192b2f572c304821f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5cde0ab6a4474f9983dbad7a465217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\1366564830.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 04:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.354600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 3 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Accuracy: 0.7596, AUC: 0.8113\n",
      "\n",
      "Fold 4/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cb445956fc4202bd306af68f0202ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a06632d30ba47819fa45066c02d2279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\1366564830.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.438200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.439700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.369600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 4 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Accuracy: 0.7651, AUC: 0.8125\n",
      "\n",
      "Fold 5/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a0cbfb20fc4a0db0dd1c5c2bf24e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fd95e2532c464c9a9af52d8d9c22d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\1366564830.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.529100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.470100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.435900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.368800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 5 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Accuracy: 0.7478, AUC: 0.8025\n",
      "\n",
      "============================================================\n",
      "Cross-validation training completed!\n",
      "Overall CV - Accuracy: 0.7616, AUC: 0.8115\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold Cross-Validation Training with Immediate Test Predictions\n",
    "# Train 5 models using cross-validation, generate bot_prob_from_desc feature\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions), dim=-1)\n",
    "    bot_probs = probs[:, 1].numpy()\n",
    "    pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, pred_labels),\n",
    "        'f1': f1_score(labels, pred_labels, average='weighted'),\n",
    "        'auc': roc_auc_score(labels, bot_probs)\n",
    "    }\n",
    "\n",
    "# Training arguments optimized for Colab\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,                    # Reduced for faster CV\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000,                    # Reduced logging frequency\n",
    "    eval_strategy=\"no\",                    # Skip evaluation during training for speed\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Setup 5-fold cross-validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays for easier indexing\n",
    "train_texts_array = np.array(train_texts)\n",
    "train_labels_array = np.array(train_labels)\n",
    "\n",
    "# Store predictions for each fold\n",
    "fold_predictions = np.zeros(len(train_texts))\n",
    "test_predictions = []  # Store test predictions from each fold\n",
    "\n",
    "# Create test dataset once\n",
    "test_dataset = Dataset.from_dict({'text': test_texts, 'labels': [0] * len(test_texts)})  # Dummy labels\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Starting 5-fold cross-validation training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_texts_array, train_labels_array)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Split data for this fold\n",
    "    fold_train_texts = train_texts_array[train_idx].tolist()\n",
    "    fold_train_labels = train_labels_array[train_idx].tolist()\n",
    "    fold_val_texts = train_texts_array[val_idx].tolist()\n",
    "    fold_val_labels = train_labels_array[val_idx].tolist()\n",
    "\n",
    "    # Create datasets for this fold\n",
    "    fold_train_dataset = Dataset.from_dict({'text': fold_train_texts, 'labels': fold_train_labels})\n",
    "    fold_val_dataset = Dataset.from_dict({'text': fold_val_texts, 'labels': fold_val_labels})\n",
    "\n",
    "    # Tokenize datasets\n",
    "    fold_train_tokenized = fold_train_dataset.map(tokenize_function, batched=True)\n",
    "    fold_val_tokenized = fold_val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Create fresh model for this fold\n",
    "    model = create_model()\n",
    "\n",
    "    # Create trainer for this fold\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=fold_train_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Get predictions on validation set\n",
    "    val_predictions = trainer.predict(fold_val_tokenized)\n",
    "    val_probs = torch.nn.functional.softmax(torch.tensor(val_predictions.predictions), dim=-1)\n",
    "    val_bot_probs = val_probs[:, 1].numpy()  # Bot probabilities\n",
    "\n",
    "    # Store validation predictions in the correct positions\n",
    "    fold_predictions[val_idx] = val_bot_probs\n",
    "\n",
    "    # Get predictions on test set immediately\n",
    "    print(f\"Generating test predictions with fold {fold + 1} model...\")\n",
    "    test_pred = trainer.predict(test_tokenized)\n",
    "    test_probs = torch.nn.functional.softmax(torch.tensor(test_pred.predictions), dim=-1)\n",
    "    test_bot_probs = test_probs[:, 1].numpy()\n",
    "    test_predictions.append(test_bot_probs)\n",
    "\n",
    "    # Calculate fold performance\n",
    "    val_pred_labels = np.argmax(val_predictions.predictions, axis=1)\n",
    "    fold_accuracy = accuracy_score(fold_val_labels, val_pred_labels)\n",
    "    fold_auc = roc_auc_score(fold_val_labels, val_bot_probs)\n",
    "    print(f\"Fold {fold + 1} - Accuracy: {fold_accuracy:.4f}, AUC: {fold_auc:.4f}\")\n",
    "\n",
    "    # Clear GPU memory - now safe to delete\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Cross-validation training completed!\")\n",
    "overall_auc = roc_auc_score(train_labels, fold_predictions)\n",
    "overall_accuracy = accuracy_score(train_labels, (fold_predictions > 0.5).astype(int))\n",
    "print(f\"Overall CV - Accuracy: {overall_accuracy:.4f}, AUC: {overall_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e9b6d9",
   "metadata": {},
   "source": [
    "The single column of probabilities are stored as a csv file in `train_output_path` and `test_output_path`.  \n",
    "  \n",
    "Edit these accordingly if they are to be saved somewhere else. Changing this location has downstream implications as it these locations will be referenced during the execution of the main pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6254e259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training bot_prob_from_desc saved to: data/train_bot_prob_from_desc.csv\n",
      "Test bot_prob_from_desc saved to: data/test_bot_prob_from_desc.csv\n"
     ]
    }
   ],
   "source": [
    "# Average test predictions across all folds\n",
    "ensemble_test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "# Save bot_prob_from_desc directly as CSV\n",
    "train_bot_prob_df = pd.DataFrame({'bot_prob_from_desc': fold_predictions})\n",
    "test_bot_prob_df = pd.DataFrame({'bot_prob_from_desc': ensemble_test_predictions})\n",
    "\n",
    "train_output_path = \"data/train_bot_prob_from_desc.csv\"\n",
    "test_output_path = \"data/test_bot_prob_from_desc.csv\"\n",
    "\n",
    "train_bot_prob_df.to_csv(train_output_path, index=False)\n",
    "test_bot_prob_df.to_csv(test_output_path, index=False)\n",
    "\n",
    "print(f\"\\nTraining bot_prob_from_desc saved to: {train_output_path}\")\n",
    "print(f\"Test bot_prob_from_desc saved to: {test_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5384e5",
   "metadata": {},
   "source": [
    "We will proceed to train the other feature column - bot_prob_from_cat, which produces a single column reflecting probabilities predicted by the trained model that the user is a bot based on all the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cac368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 26206 samples\n",
      "Test dataset size: 11232 samples\n"
     ]
    }
   ],
   "source": [
    "def load_extract_data_cat():\n",
    "    \"\"\"Load train and test data\"\"\"\n",
    "    train_data_path = \"data/train.csv\"\n",
    "    test_data_path = \"data/test.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    # Extract features as JSON with description first\n",
    "    train_texts = []\n",
    "    for _, row in train_df.iterrows():\n",
    "        data = {\n",
    "            \"description\": row['description'] if pd.notna(row['description']) else \"\",\n",
    "            \"lang\": row['lang'] if pd.notna(row['lang']) else \"\",\n",
    "            \"location\": row['location'] if pd.notna(row['location']) else \"\",\n",
    "            \"screen_name\": row['screen_name'] if pd.notna(row['screen_name']) else \"\"\n",
    "        }\n",
    "        train_texts.append(json.dumps(data))\n",
    "\n",
    "    train_labels = train_df['target'].tolist()\n",
    "\n",
    "    test_texts = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        data = {\n",
    "            \"description\": row['description'] if pd.notna(row['description']) else \"\",\n",
    "            \"lang\": row['lang'] if pd.notna(row['lang']) else \"\",\n",
    "            \"location\": row['location'] if pd.notna(row['location']) else \"\",\n",
    "            \"screen_name\": row['screen_name'] if pd.notna(row['screen_name']) else \"\"\n",
    "        }\n",
    "        test_texts.append(json.dumps(data))\n",
    "\n",
    "    print(f\"Train dataset size: {len(train_df)} samples\")\n",
    "    print(f\"Test dataset size: {len(test_df)} samples\")\n",
    "\n",
    "    return train_texts, train_labels, test_texts, train_df, test_df\n",
    "\n",
    "# Load the preprocessed data\n",
    "train_texts, train_labels, test_texts, train_df, test_df = load_extract_data_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44c98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e50646f04b45c7aadda03b7caf7eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-fold cross-validation training...\n",
      "============================================================\n",
      "\n",
      "Fold 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d95fd40fa3f426e9cd63aacd80cb099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3788d1ce290405591fba744bf403e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\4071851857.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.539600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.456200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.415900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.343500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.338900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 1 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 0.7751, AUC: 0.8272\n",
      "\n",
      "Fold 2/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aee154c49b34d6992ddcf52c71e3de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95616748a24d42b2bbab1a6cae9b0931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\4071851857.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.543900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.365500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.338600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 2 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Accuracy: 0.7783, AUC: 0.8372\n",
      "\n",
      "Fold 3/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f255ebbc40b747bb8744b05d54d6cb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14bb896f4794a8ca1fbf093027ed106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\4071851857.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 3...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.542000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.325300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 3 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Accuracy: 0.7598, AUC: 0.8168\n",
      "\n",
      "Fold 4/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aecca806b04d8a944f5c4502cd294b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a732c3c3a6894dee944728e0fa2e227d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\4071851857.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 4...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.421900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.421200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.348000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.346200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 4 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Accuracy: 0.7686, AUC: 0.8231\n",
      "\n",
      "Fold 5/5\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f880a7f5b474d9989d56884eca210b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4412db27951141ab8125c778a24ceed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7740\\4071851857.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7863' max='7863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7863/7863 05:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.339400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions with fold 5 model...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML-Twitter-Bot-Detection\\venv\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Accuracy: 0.7605, AUC: 0.8152\n",
      "\n",
      "============================================================\n",
      "Cross-validation training completed!\n",
      "Overall CV - Accuracy: 0.7684, AUC: 0.8231\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold Cross-Validation Training with Immediate Test Predictions\n",
    "# Train 5 models using cross-validation, generate bot_prob_from_desc feature\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions), dim=-1)\n",
    "    bot_probs = probs[:, 1].numpy()\n",
    "    pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, pred_labels),\n",
    "        'f1': f1_score(labels, pred_labels, average='weighted'),\n",
    "        'auc': roc_auc_score(labels, bot_probs)\n",
    "    }\n",
    "\n",
    "# Training arguments optimized for Colab\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,                    # Reduced for faster CV\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000,                    # Reduced logging frequency\n",
    "    eval_strategy=\"no\",                    # Skip evaluation during training for speed\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Setup 5-fold cross-validation\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert to numpy arrays for easier indexing\n",
    "train_texts_array = np.array(train_texts)\n",
    "train_labels_array = np.array(train_labels)\n",
    "\n",
    "# Store predictions for each fold\n",
    "fold_predictions_cat = np.zeros(len(train_texts))\n",
    "test_predictions_cat = []  # Store test predictions from each fold\n",
    "\n",
    "# Create test dataset once\n",
    "test_dataset = Dataset.from_dict({'text': test_texts, 'labels': [0] * len(test_texts)})  # Dummy labels\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Starting 5-fold cross-validation training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_texts_array, train_labels_array)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Split data for this fold\n",
    "    fold_train_texts = train_texts_array[train_idx].tolist()\n",
    "    fold_train_labels = train_labels_array[train_idx].tolist()\n",
    "    fold_val_texts = train_texts_array[val_idx].tolist()\n",
    "    fold_val_labels = train_labels_array[val_idx].tolist()\n",
    "\n",
    "    # Create datasets for this fold\n",
    "    fold_train_dataset = Dataset.from_dict({'text': fold_train_texts, 'labels': fold_train_labels})\n",
    "    fold_val_dataset = Dataset.from_dict({'text': fold_val_texts, 'labels': fold_val_labels})\n",
    "\n",
    "    # Tokenize datasets\n",
    "    fold_train_tokenized = fold_train_dataset.map(tokenize_function, batched=True)\n",
    "    fold_val_tokenized = fold_val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Create fresh model for this fold\n",
    "    model = create_model()\n",
    "\n",
    "    # Create trainer for this fold\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=fold_train_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Training fold {fold + 1}...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Get predictions on validation set\n",
    "    val_predictions = trainer.predict(fold_val_tokenized)\n",
    "    val_probs = torch.nn.functional.softmax(torch.tensor(val_predictions.predictions), dim=-1)\n",
    "    val_bot_probs = val_probs[:, 1].numpy()  # Bot probabilities\n",
    "\n",
    "    # Store validation predictions in the correct positions\n",
    "    fold_predictions_cat[val_idx] = val_bot_probs\n",
    "\n",
    "    # Get predictions on test set immediately\n",
    "    print(f\"Generating test predictions with fold {fold + 1} model...\")\n",
    "    test_pred = trainer.predict(test_tokenized)\n",
    "    test_probs = torch.nn.functional.softmax(torch.tensor(test_pred.predictions), dim=-1)\n",
    "    test_bot_probs = test_probs[:, 1].numpy()\n",
    "    test_predictions_cat.append(test_bot_probs)\n",
    "\n",
    "    # Calculate fold performance\n",
    "    val_pred_labels = np.argmax(val_predictions.predictions, axis=1)\n",
    "    fold_accuracy = accuracy_score(fold_val_labels, val_pred_labels)\n",
    "    fold_auc = roc_auc_score(fold_val_labels, val_bot_probs)\n",
    "    print(f\"Fold {fold + 1} - Accuracy: {fold_accuracy:.4f}, AUC: {fold_auc:.4f}\")\n",
    "\n",
    "    # Clear GPU memory - now safe to delete\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Cross-validation training completed!\")\n",
    "overall_auc = roc_auc_score(train_labels, fold_predictions_cat)\n",
    "overall_accuracy = accuracy_score(train_labels, (fold_predictions_cat > 0.5).astype(int))\n",
    "print(f\"Overall CV - Accuracy: {overall_accuracy:.4f}, AUC: {overall_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090effbe",
   "metadata": {},
   "source": [
    "Similarly, the columns will be saved as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc8b8056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training bot_prob_from_desc saved to: data/train_bot_prob_from_cat.csv\n",
      "Test bot_prob_from_desc saved to: data/test_bot_prob_from_cat.csv\n"
     ]
    }
   ],
   "source": [
    "# Average test predictions across all folds\n",
    "ensemble_test_predictions_cat = np.mean(test_predictions_cat, axis=0)\n",
    "\n",
    "# Save bot_prob_from_desc directly as CSV\n",
    "train_bot_prob_df = pd.DataFrame({'bot_prob_from_cat': fold_predictions_cat})\n",
    "test_bot_prob_df = pd.DataFrame({'bot_prob_from_cat': ensemble_test_predictions_cat})\n",
    "\n",
    "train_output_path = \"data/train_bot_prob_from_cat.csv\"\n",
    "test_output_path = \"data/test_bot_prob_from_cat.csv\"\n",
    "\n",
    "train_bot_prob_df.to_csv(train_output_path, index=False)\n",
    "test_bot_prob_df.to_csv(test_output_path, index=False)\n",
    "\n",
    "print(f\"\\nTraining bot_prob_from_desc saved to: {train_output_path}\")\n",
    "print(f\"Test bot_prob_from_desc saved to: {test_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5815f7c",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3624e0c7",
   "metadata": {},
   "source": [
    "Edit `train_path` and `test_path` if the train and test datasets are not in the specified paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb23444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5d8b4",
   "metadata": {},
   "source": [
    "### Data preprocessing and Feature engineering  \n",
    "In this section we conduct data preprocessing and feature engineering. The LLM augmented features from earlier is appended to the dataframe at the end. Please update the `read_csv` paths if the csv files where saved to different locations paths than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae205f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform some features\n",
    "log_features = ['favourites_count', 'followers_count', 'friends_count', 'statuses_count','average_tweets_per_day']\n",
    "for feature in log_features:\n",
    "    train_df[f'log_{feature}'] = np.log1p(train_df[feature])\n",
    "    test_df[f'log_{feature}'] = np.log1p(test_df[feature])\n",
    "\n",
    "# add binary indicator if there is description\n",
    "train_df[f'description_ind'] = (~train_df['description'].isna()).astype(int)\n",
    "test_df[f'description_ind'] = (~test_df['description'].isna()).astype(int)\n",
    "\n",
    "# add description length feature\n",
    "train_df['desc_length'] = train_df['description'].fillna('').str.len()\n",
    "test_df['desc_length'] = test_df['description'].fillna('').str.len()\n",
    "\n",
    "# convert bool features to binary\n",
    "bool_cols = ['default_profile', 'default_profile_image', 'geo_enabled', 'verified']\n",
    "for col in bool_cols:\n",
    "    train_df[f'{col}_bin'] = train_df[col].astype(int)\n",
    "    test_df[f'{col}_bin'] = test_df[col].astype(int)\n",
    "\n",
    "# Create separate dataframes for CatBoost (before dropping categorical features)\n",
    "train_df_cat = train_df.copy()\n",
    "test_df_cat = test_df.copy()\n",
    "\n",
    "# Fill missing values for categorical features in CatBoost dataframes\n",
    "train_df_cat['lang'] = train_df_cat['lang'].fillna(\"unknown\")\n",
    "test_df_cat['lang'] = test_df_cat['lang'].fillna(\"unknown\")\n",
    "train_df_cat['location'] = train_df_cat['location'].fillna(\"unknown\")\n",
    "test_df_cat['location'] = test_df_cat['location'].fillna(\"unknown\")\n",
    "train_df_cat['description'] = train_df_cat['description'].fillna(\"unknown\")\n",
    "test_df_cat['description'] = test_df_cat['description'].fillna(\"unknown\")\n",
    "\n",
    "# Drop only non-categorical features for CatBoost\n",
    "cat_features_to_drop = ['created_at', 'profile_background_image_url', 'profile_image_url', 'screen_name', 'id']\n",
    "train_df_cat = train_df_cat.drop(cat_features_to_drop, axis=1)\n",
    "test_df_cat = test_df_cat.drop(cat_features_to_drop, axis=1)\n",
    "\n",
    "# encode categorical features with OneHotEncoder for XGBoost/LightGBM\n",
    "cat_cols = ['lang', 'location']\n",
    "for col in cat_cols:\n",
    "    train_df[col] = train_df[col].fillna(\"unknown\")\n",
    "    test_df[col] = test_df[col].fillna(\"unknown\")\n",
    "\n",
    "    # Get top 30 most frequent categories\n",
    "    value_counts = train_df[col].value_counts()\n",
    "    top_categories = value_counts.head(30).index.tolist()\n",
    "\n",
    "    # Group less frequent categories as 'other'\n",
    "    train_col = train_df[col].apply(lambda x: x if x in top_categories else 'other')\n",
    "    test_col = test_df[col].apply(lambda x: x if x in top_categories else 'other')\n",
    "\n",
    "    # Apply one-hot encoding\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    train_encoded = encoder.fit_transform(train_col.values.reshape(-1, 1))\n",
    "    test_encoded = encoder.transform(test_col.values.reshape(-1, 1))\n",
    "\n",
    "    # Create column names and DataFrames with sanitized names\n",
    "    def sanitize_feature_name(name):\n",
    "        # Replace special characters with underscore\n",
    "        name = re.sub(r'[^\\w\\s]', '_', str(name))\n",
    "        # Replace spaces with underscore\n",
    "        name = re.sub(r'\\s+', '_', name)\n",
    "        # Remove consecutive underscores\n",
    "        name = re.sub(r'_+', '_', name)\n",
    "        # Remove leading/trailing underscores\n",
    "        name = name.strip('_')\n",
    "        return name\n",
    "\n",
    "    feature_names = [f'{col}_{sanitize_feature_name(category)}' for category in encoder.categories_[0]]\n",
    "    train_encoded_df = pd.DataFrame(train_encoded, columns=feature_names, index=train_df.index)\n",
    "    test_encoded_df = pd.DataFrame(test_encoded, columns=feature_names, index=test_df.index)\n",
    "\n",
    "    # Concatenate with original DataFrames\n",
    "    train_df = pd.concat([train_df, train_encoded_df], axis=1)\n",
    "    test_df = pd.concat([test_df, test_encoded_df], axis=1)\n",
    "\n",
    "# drop features\n",
    "# drop id to reduce noise\n",
    "features_to_drop = ['created_at', 'description', 'profile_background_image_url',\n",
    "                    'profile_image_url', 'screen_name','default_profile', 'default_profile_image', 'geo_enabled', 'verified',\n",
    "                    'lang', 'location', 'id']\n",
    "train_df = train_df.drop(features_to_drop, axis=1)\n",
    "test_df = test_df.drop(features_to_drop, axis=1)\n",
    "\n",
    "# append the llm augmented features from earlier\n",
    "# prob from all cat features\n",
    "train_df['bot_prob_from_cat'] = pd.read_csv('data/train_bot_prob_from_cat.csv')['bot_prob_from_cat']\n",
    "test_df['bot_prob_from_cat'] = pd.read_csv('data/test_bot_prob_from_cat.csv')['bot_prob_from_cat']\n",
    "train_df_cat['bot_prob_from_cat'] = pd.read_csv('data/train_bot_prob_from_cat.csv')['bot_prob_from_cat']\n",
    "test_df_cat['bot_prob_from_cat'] = pd.read_csv('data/train_bot_prob_from_cat.csv')['bot_prob_from_cat']\n",
    "\n",
    "# add desc feature from other llm output\n",
    "train_df['bot_prob_from_desc'] = pd.read_csv('data/train_bot_prob_from_desc.csv')['bot_prob_from_desc']\n",
    "test_df['bot_prob_from_desc'] = pd.read_csv('data/test_bot_prob_from_desc.csv')['bot_prob_from_desc']\n",
    "train_df_cat['bot_prob_from_desc'] = pd.read_csv('data/train_bot_prob_from_desc.csv')['bot_prob_from_desc']\n",
    "test_df_cat['bot_prob_from_desc'] = pd.read_csv('data/test_bot_prob_from_desc.csv')['bot_prob_from_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ddae979",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df, train_df_cat, test_df_cat]:\n",
    "    # Network interaction feature\n",
    "    df['network_log'] = df['log_friends_count'] * df['log_followers_count']\n",
    "\n",
    "    # Average metrics per tweet (using log-transformed features, avoid division by zero)\n",
    "    df['avg_faves_per_tweets'] = df['log_favourites_count'] / (df['log_statuses_count'] + 1e-8)\n",
    "    df['avg_followers_per_tweet'] = df['log_followers_count'] / (df['log_statuses_count'] + 1e-8)\n",
    "    df['avg_friends_per_tweet'] = df['log_friends_count'] / (df['log_statuses_count'] + 1e-8)\n",
    "\n",
    "    # Daily acquisition rates (log-transformed, avoid division by zero)\n",
    "    df['follower_acq_rate'] = np.log1p(df['followers_count'] / (df['account_age_days'] + 1))\n",
    "    df['friends_acq_rate'] = np.log1p(df['friends_count'] / (df['account_age_days'] + 1))\n",
    "    df['favs_rate'] = np.log1p(df['favourites_count'] / (df['account_age_days'] + 1))\n",
    "\n",
    "    # Behavioral ratios (bots often have unusual patterns)\n",
    "    df['followers_friends_ratio'] = df['followers_count'] / (df['friends_count'] + 1)\n",
    "    df['tweets_per_follower'] = df['statuses_count'] / (df['followers_count'] + 1)\n",
    "    df['favorites_per_tweet'] = df['favourites_count'] / (df['statuses_count'] + 1)\n",
    "\n",
    "    # Activity intensity\n",
    "    df['total_activity'] = df['statuses_count'] + df['favourites_count']\n",
    "    df['activity_per_day'] = df['total_activity'] / (df['account_age_days'] + 1)\n",
    "\n",
    "# Default profile indicators (only for train_df and test_df that have _bin columns)\n",
    "for df in [train_df, test_df]:\n",
    "    df['has_defaults'] = (df['default_profile_bin'] + df['default_profile_image_bin'])\n",
    "    df['profile_completeness'] = df['description_ind'] + df['geo_enabled_bin'] + df['verified_bin']\n",
    "\n",
    "# For CatBoost dataframes (they have original boolean columns)\n",
    "for df in [train_df_cat, test_df_cat]:\n",
    "    df['has_defaults'] = (df['default_profile'].astype(int) + df['default_profile_image'].astype(int))\n",
    "    df['profile_completeness'] = df['description_ind'] + df['geo_enabled'].astype(int) + df['verified'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3ed44",
   "metadata": {},
   "source": [
    "### Training and Evaluation\n",
    "In this section we conduct training and evaluation.   \n",
    "  \n",
    "This pipeline uses the full training data. To see the version of the pipeline where the training data is further split into a validation set for fast iterative testing, view the last 2 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b659f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 95 features for XGBoost/LightGBM\n",
      "Using 40 features for CatBoost (including 7 categorical features)\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 10}\n",
      "Best XGBoost CV AUC: 0.9480\n",
      "Best CatBoost params: {'depth': 6, 'iterations': 200, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
      "Best CatBoost CV AUC: 0.9472\n",
      "\n",
      "Cross-Validation AUC: 0.9480\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for XGBoost and LightGBM\n",
    "feature_cols = [col for col in train_df.columns if col != 'target']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['target']\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features for XGBoost/LightGBM\")\n",
    "\n",
    "# Prepare data for CatBoost with categorical features\n",
    "cat_feature_cols = [col for col in train_df_cat.columns if col != 'target']\n",
    "X_cat = train_df_cat[cat_feature_cols]\n",
    "y_cat = train_df_cat['target']\n",
    "\n",
    "# Identify categorical features for CatBoost\n",
    "cat_features = ['default_profile', 'default_profile_image', 'geo_enabled', 'verified', 'lang', 'location', 'description']\n",
    "cat_feature_indices = [X_cat.columns.get_loc(col) for col in cat_features if col in X_cat.columns]\n",
    "\n",
    "print(f\"Using {len(cat_feature_cols)} features for CatBoost (including {len(cat_feature_indices)} categorical features)\")\n",
    "\n",
    "# Train XGBoost with hyperparameter tuning\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1, 10]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "xgb_grid_search.fit(X, y)\n",
    "\n",
    "best_xgb = xgb_grid_search.best_estimator_\n",
    "print(f\"Best XGBoost params: {xgb_grid_search.best_params_}\")\n",
    "print(f\"Best XGBoost CV AUC: {xgb_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train CatBoost with hyperparameter tuning\n",
    "cat_param_grid = {\n",
    "    'iterations': [100, 200],\n",
    "    'depth': [4, 6],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'l2_leaf_reg': [3, 5]\n",
    "}\n",
    "\n",
    "cat_model = CatBoostClassifier(random_seed=42, verbose=False, cat_features=cat_feature_indices)\n",
    "cat_grid_search = GridSearchCV(cat_model, cat_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "cat_grid_search.fit(X_cat, y_cat)\n",
    "\n",
    "best_cat = cat_grid_search.best_estimator_\n",
    "print(f\"Best CatBoost params: {cat_grid_search.best_params_}\")\n",
    "print(f\"Best CatBoost CV AUC: {cat_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train LightGBM\n",
    "lgbm_model = LGBMClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgbm_model.fit(X, y)\n",
    "\n",
    "# Store models and CV scores\n",
    "ensemble_models = {\n",
    "    'xgboost': best_xgb,\n",
    "    'catboost': best_cat,\n",
    "    'lightgbm': lgbm_model\n",
    "}\n",
    "\n",
    "cv_auc = xgb_grid_search.best_score_\n",
    "print(f\"\\nCross-Validation AUC: {cv_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df75bd2",
   "metadata": {},
   "source": [
    "### Submission generation\n",
    "The final predictions are generated and saved to 'data' folder as a csv file with the naming convention: `submission-{cv_auc:.5f}.csv`. Please edit the save path accordingly if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ffd45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to data/submission-0.94801.csv\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df[feature_cols]\n",
    "X_test_cat = test_df_cat[cat_feature_cols]\n",
    "\n",
    "# Get predictions from each model\n",
    "predictions_xgb = ensemble_models['xgboost'].predict_proba(X_test)[:, 1]\n",
    "predictions_cat = ensemble_models['catboost'].predict_proba(X_test_cat)[:, 1]\n",
    "predictions_lgbm = ensemble_models['lightgbm'].predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Ensemble predictions with weighted average\n",
    "predictions = (2 * predictions_xgb + 1 * predictions_cat + 1 * predictions_lgbm) / 4\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'index': range(len(predictions)),\n",
    "    'target': predictions\n",
    "})\n",
    "output_path = f\"data/submission-{cv_auc:.5f}.csv\"\n",
    "submission.to_csv(output_path, index=False)\n",
    "print(f\"Submission saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e12d1e",
   "metadata": {},
   "source": [
    "# DO NOT RUN\n",
    "The below cell is to illustrate the pipeline during the iterative testing phase, where the training data is split into train and validation for faster iterative testing, as well as to ensure that the final models are not overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "233b91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa34eb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 95 features for XGBoost/LightGBM\n",
      "Using 40 features for CatBoost (including 7 categorical features)\n",
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 10}\n",
      "Best XGBoost CV AUC: 0.9457\n",
      "Best CatBoost params: {'depth': 6, 'iterations': 200, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
      "Best CatBoost CV AUC: 0.9452\n",
      "\n",
      "Model Performance Comparison:\n",
      "==================================================\n",
      "XGBoost Val AUC: 0.9517\n",
      "CatBoost Val AUC: 0.9508\n",
      "LightGBM Val AUC: 0.9508\n",
      "Ensemble Val AUC: 0.9528\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for XGBoost and LightGBM\n",
    "feature_cols = [col for col in train_df.columns if col != 'target']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['target']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Using {len(feature_cols)} features for XGBoost/LightGBM\")\n",
    "\n",
    "# Prepare data for CatBoost with categorical features\n",
    "cat_feature_cols = [col for col in train_df_cat.columns if col != 'target']\n",
    "X_cat = train_df_cat[cat_feature_cols]\n",
    "y_cat = train_df_cat['target']\n",
    "\n",
    "X_cat_train, X_cat_val, y_cat_train, y_cat_val = train_test_split(X_cat, y_cat, test_size=0.2, random_state=42, stratify=y_cat)\n",
    "\n",
    "# Identify categorical features for CatBoost\n",
    "cat_features = ['default_profile', 'default_profile_image', 'geo_enabled', 'verified', 'lang', 'location', 'description']\n",
    "cat_feature_indices = [X_cat.columns.get_loc(col) for col in cat_features if col in X_cat.columns]\n",
    "\n",
    "print(f\"Using {len(cat_feature_cols)} features for CatBoost (including {len(cat_feature_indices)} categorical features)\")\n",
    "\n",
    "# Train XGBoost with hyperparameter tuning\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1, 10]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgb = xgb_grid_search.best_estimator_\n",
    "print(f\"Best XGBoost params: {xgb_grid_search.best_params_}\")\n",
    "print(f\"Best XGBoost CV AUC: {xgb_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train CatBoost with hyperparameter tuning\n",
    "\n",
    "cat_param_grid = {\n",
    "    'iterations': [100, 200],\n",
    "    'depth': [4, 6],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'l2_leaf_reg': [3, 5]\n",
    "}\n",
    "\n",
    "cat_model = CatBoostClassifier(random_seed=42, verbose=False, cat_features=cat_feature_indices)\n",
    "cat_grid_search = GridSearchCV(cat_model, cat_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "cat_grid_search.fit(X_cat_train, y_cat_train)\n",
    "\n",
    "best_cat = cat_grid_search.best_estimator_\n",
    "print(f\"Best CatBoost params: {cat_grid_search.best_params_}\")\n",
    "print(f\"Best CatBoost CV AUC: {cat_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train LightGBM\n",
    "\n",
    "lgbm_model = LGBMClassifier(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42, verbose=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate individual models\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# XGBoost predictions\n",
    "y_val_proba_xgb = best_xgb.predict_proba(X_val)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_val, y_val_proba_xgb)\n",
    "print(f\"XGBoost Val AUC: {auc_xgb:.4f}\")\n",
    "\n",
    "# CatBoost predictions (using categorical data)\n",
    "y_cat_val_proba_cat = best_cat.predict_proba(X_cat_val)[:, 1]\n",
    "auc_cat = roc_auc_score(y_cat_val, y_cat_val_proba_cat)\n",
    "print(f\"CatBoost Val AUC: {auc_cat:.4f}\")\n",
    "\n",
    "# LightGBM predictions\n",
    "y_val_proba_lgbm = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "auc_lgbm = roc_auc_score(y_val, y_val_proba_lgbm)\n",
    "print(f\"LightGBM Val AUC: {auc_lgbm:.4f}\")\n",
    "\n",
    "# Manual ensemble predictions (weighted average)\n",
    "y_train_proba_xgb = best_xgb.predict_proba(X_train)[:, 1]\n",
    "y_train_proba_cat = best_cat.predict_proba(X_cat_train)[:, 1]\n",
    "y_train_proba_lgbm = lgbm_model.predict_proba(X_train)[:, 1]\n",
    "# higher weight to XGBoost\n",
    "y_train_proba = (2 * y_train_proba_xgb + 1 * y_train_proba_cat + 1 * y_train_proba_lgbm) / 4\n",
    "y_train_pred = (y_train_proba >= 0.5).astype(int)\n",
    "\n",
    "y_val_proba = (2 * y_val_proba_xgb + 1 * y_cat_val_proba_cat + 1 * y_val_proba_lgbm) / 4\n",
    "y_val_pred = (y_val_proba >= 0.5).astype(int)\n",
    "\n",
    "train_metrics = {\n",
    "    'auc': roc_auc_score(y_train, y_train_proba),\n",
    "    'accuracy': accuracy_score(y_train, y_train_pred),\n",
    "    'precision': precision_score(y_train, y_train_pred),\n",
    "    'recall': recall_score(y_train, y_train_pred),\n",
    "    'f1': f1_score(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "val_metrics = {\n",
    "    'auc': roc_auc_score(y_val, y_val_proba),\n",
    "    'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "    'precision': precision_score(y_val, y_val_pred),\n",
    "    'recall': recall_score(y_val, y_val_pred),\n",
    "    'f1': f1_score(y_val, y_val_pred)\n",
    "}\n",
    "\n",
    "print(f\"Ensemble Val AUC: {val_metrics['auc']:.4f}\")\n",
    "\n",
    "# Store models and feature columns\n",
    "ensemble_models = {\n",
    "    'xgboost': best_xgb,\n",
    "    'catboost': best_cat,\n",
    "    'lightgbm': lgbm_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699ca048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - AUC: 0.9789, Acc: 0.9287, Prec: 0.9348, Rec: 0.8464, F1: 0.8884\n",
      "Val   - AUC: 0.9528, Acc: 0.8932, Prec: 0.8800, Rec: 0.7888, F1: 0.8319\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train - AUC: {train_metrics['auc']:.4f}, Acc: {train_metrics['accuracy']:.4f}, Prec: {train_metrics['precision']:.4f}, Rec: {train_metrics['recall']:.4f}, F1: {train_metrics['f1']:.4f}\")\n",
    "print(f\"Val   - AUC: {val_metrics['auc']:.4f}, Acc: {val_metrics['accuracy']:.4f}, Prec: {val_metrics['precision']:.4f}, Rec: {val_metrics['recall']:.4f}, F1: {val_metrics['f1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
